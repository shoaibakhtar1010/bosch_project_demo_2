{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01 \u2014 Training notebook (MLOps template)\\n",
        "\\n",
        "This notebook keeps *logic in the package* and only orchestrates:\\n",
        "- dataset download via **kagglehub**\\n",
        "- manifest build + split\\n",
        "- model training\\n",
        "- saving artifacts (checkpoint + labels)\\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If running locally, install the project in editable mode first:\\n",
        "# !pip install -e '.[dev]'\\n",
        "\\n",
        "import os\\n",
        "from pathlib import Path\\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import kagglehub\\n",
        "\\n",
        "# Download latest version\\n",
        "dataset_dir = Path(kagglehub.dataset_download(\\n",
        "    'ninadmehendale/multimodal-iris-fingerprint-biometric-data'\\n",
        "))\\n",
        "print('Path to dataset files:', dataset_dir)\\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: inspect structure\\n",
        "from itertools import islice\\n",
        "\\n",
        "paths = list(islice(dataset_dir.rglob('*'), 50))\\n",
        "for p in paths[:30]:\\n",
        "    print(p)\\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from mmbiometric.data.manifest import build_manifest\\n",
        "from mmbiometric.data.split import split_manifest\\n",
        "\\n",
        "run_dir = Path('runs/notebook_run')\\n",
        "run_dir.mkdir(parents=True, exist_ok=True)\\n",
        "\\n",
        "# subject_regex may need tweaking based on the dataset's filename/folder naming\\n",
        "manifest_path = build_manifest(dataset_dir, run_dir / 'manifest.parquet', subject_regex=r'(\\\\d+)')\\n",
        "splits = split_manifest(manifest_path, out_dir=run_dir / 'splits', val_fraction=0.2, seed=42)\\n",
        "print('train manifest:', splits.train_manifest)\\n",
        "print('val manifest:', splits.val_manifest)\\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\\n",
        "train_df = pd.read_parquet(splits.train_manifest)\\n",
        "labels = sorted(train_df['subject_id'].astype(str).unique())\\n",
        "label_to_idx = {lab: i for i, lab in enumerate(labels)}\\n",
        "idx_to_label = {i: lab for lab, i in label_to_idx.items()}\\n",
        "len(labels), labels[:10]\\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\\n",
        "from torch.utils.data import DataLoader\\n",
        "\\n",
        "from mmbiometric.data.dataset import MultimodalBiometricDataset\\n",
        "from mmbiometric.data.transforms import default_image_transform\\n",
        "from mmbiometric.models.multimodal_net import MultimodalNet\\n",
        "from mmbiometric.training.loops import fit\\n",
        "from mmbiometric.utils.seed import seed_everything\\n",
        "\\n",
        "seed_everything(42)\\n",
        "\\n",
        "image_size = 224\\n",
        "tfm = default_image_transform(image_size)\\n",
        "\\n",
        "train_ds = MultimodalBiometricDataset(splits.train_manifest, tfm, tfm, label_to_idx)\\n",
        "val_ds = MultimodalBiometricDataset(splits.val_manifest, tfm, tfm, label_to_idx)\\n",
        "\\n",
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=2)\\n",
        "val_loader = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=2)\\n",
        "\\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\\n",
        "\\n",
        "model = MultimodalNet(backbone='resnet18', embedding_dim=256, num_classes=len(labels), dropout=0.1)\\n",
        "model.to(device)\\n",
        "\\n",
        "res = fit(\\n",
        "    model=model,\\n",
        "    train_loader=train_loader,\\n",
        "    val_loader=val_loader,\\n",
        "    epochs=3,\\n",
        "    lr=3e-4,\\n",
        "    weight_decay=1e-4,\\n",
        "    device=device,\\n",
        "    out_dir=run_dir,\\n",
        "    log_every=20,\\n",
        ")\\n",
        "\\n",
        "print('best val acc:', res.best_val_acc)\\n",
        "print('checkpoint:', res.best_ckpt_path)\\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\\n",
        "labels_path = run_dir / 'labels.json'\\n",
        "labels_path.write_text(json.dumps(idx_to_label, indent=2))\\n",
        "print('wrote', labels_path)\\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}